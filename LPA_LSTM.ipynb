{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d55fffd-83a0-479f-9778-1a65acb8c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8182b6-1bc4-4575-b265-dddc1abc529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Add these helpers once ====\n",
    "\n",
    "# ----------------------------\n",
    "# Repro/Device/Small Defaults\n",
    "# ----------------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LSTM_SEQ_LEN = 3\n",
    "LSTM_HIDDEN  = 16\n",
    "LSTM_LAYERS  = 1\n",
    "LSTM_EPOCHS  = 15\n",
    "LSTM_BATCH   = 64\n",
    "LSTM_LR      = 1e-2\n",
    "LSTM_DROPOUT = 0.0\n",
    "MIN_SEG = 20\n",
    "\n",
    "import numpy as np, math, torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=64, layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden, num_layers=layers, batch_first=True,\n",
    "                            dropout=dropout if layers > 1 else 0.0)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)           # [B,L,H]\n",
    "        yhat = self.fc(out[:, -1, :])   # [B,1]\n",
    "        return yhat.squeeze(-1)\n",
    "\n",
    "def build_sequences(y_window: np.ndarray, seq_len: int, start_abs_idx: int):\n",
    "    \"\"\"\n",
    "    Build sequences for a contiguous window y_window (1D float32).\n",
    "    Returns X_all [N,L,1], y_all [N], t_abs [N] with absolute target indices.\n",
    "    \"\"\"\n",
    "    L = seq_len\n",
    "    n = len(y_window)\n",
    "    if n <= L: return None, None, None\n",
    "    X = np.lib.stride_tricks.sliding_window_view(y_window, L+1)  # [N, L+1]\n",
    "    X, y = X[:, :-1], X[:, -1]                                   # [N,L], [N]\n",
    "    t_abs = np.arange(start_abs_idx + L, start_abs_idx + n, dtype=np.int64)  # absolute t of targets\n",
    "    X = X[..., None].astype(np.float32)                          # [N,L,1]\n",
    "    y = y.astype(np.float32)\n",
    "    return X, y, t_abs\n",
    "\n",
    "def fit_eval_sse(X, y, *, epochs=20, batch=128, lr=1e-3, hidden=64, layers=1, dropout=0.0, seed=0):\n",
    "    \"\"\"\n",
    "    Train one LSTM on (X,y) and return (SSE, MSE, m, yhat, resid).\n",
    "    In-sample evaluation (as in classical LR/QLR).\n",
    "    \"\"\"\n",
    "    if X is None or len(y) == 0: return math.inf, math.inf, 0, None, None\n",
    "    # torch.manual_seed(seed)\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        # torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    ds = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=True,\n",
    "                    generator=torch.Generator(device=\"cpu\"), #.manual_seed(seed),\n",
    "                    pin_memory=(DEVICE.type==\"cuda\"), num_workers=0)\n",
    "\n",
    "    model = LSTMRegressor(hidden=hidden, layers=layers, dropout=dropout).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    # in-sample SSE\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_pred, all_y = [], []\n",
    "        evl = DataLoader(ds, batch_size=512, shuffle=False, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "        for xb, yb in evl:\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "            pred = model(xb)\n",
    "            all_pred.append(pred.cpu().numpy()); all_y.append(yb.cpu().numpy())\n",
    "        yhat = np.concatenate(all_pred); y_true = np.concatenate(all_y)\n",
    "    resid = y_true - yhat\n",
    "    SSE = float(np.sum(resid**2))\n",
    "    m   = int(y_true.shape[0])\n",
    "    MSE = SSE / max(m, 1)\n",
    "    return SSE, MSE, m, yhat.astype(np.float32), resid.astype(np.float32)\n",
    "\n",
    "def draw_rademacher(m, rng):\n",
    "    return (rng.integers(0, 2, size=m) * 2 - 1).astype(np.float32)\n",
    "\n",
    "def draw_mammen(m, rng):\n",
    "    p = (np.sqrt(5)+1)/(2*np.sqrt(5))\n",
    "    a = (1 - np.sqrt(5))/2   # ≈ -0.618\n",
    "    b = (1 + np.sqrt(5))/2   # ≈  1.618\n",
    "    u = rng.random(m)\n",
    "    w = np.where(u < p, a, b).astype(np.float32)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd339b-97e4-4de4-b8c6-4b9a027dccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Likelihood_LSTM(SSE, T):\n",
    "    return -(T / 2) * np.log(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153ec4ad-a277-43ad-960a-0e20bf18174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# SEED=123\n",
    "# ----------------------------\n",
    "# Detection run (with weighted bootstrap retraining)\n",
    "# ----------------------------\n",
    "def detect_changes_with_lstm(Data_N,\n",
    "                             seq_len=LSTM_SEQ_LEN,\n",
    "                             n_0=200,\n",
    "                             jump=10,\n",
    "                             search_step=5,\n",
    "                             c=1.35,            # currently unused but kept for parity with your interface\n",
    "                             alpha=0.95,\n",
    "                             num_bootstrap=50,\n",
    "                             epochs=LSTM_EPOCHS,\n",
    "                             val_frac=0.2):\n",
    "    \"\"\"\n",
    "    Data_N: 1D numpy array (time series)\n",
    "    Returns (DataFrame, tests) with diagnostics per step.\n",
    "    Uses OOS MSE and **per-batch weighted retraining** in bootstrap if enabled.\n",
    "    \"\"\"\n",
    "    DT_N = pd.DataFrame({\"Date\": np.arange(len(Data_N)), \"N\": Data_N})\n",
    "    windows, mse_vals, rmse_vals, likelihoods, scaled_windows = [], [], [], [], []\n",
    "    tests = 0\n",
    "\n",
    "    io = Data_N.shape[0] #starting from final time\n",
    "    I_0 = list(Data_N[max(0,io-n_0):io])\n",
    "\n",
    "    n_k_minus1 = n_0 \n",
    "    I_k_minus1 = I_0\n",
    "\n",
    "    for l in range(0, Data_N.shape[0], jump):\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            io = Data_N.shape[0] - l\n",
    "\n",
    "            # arithmetic schedule\n",
    "            K = int(io / n_0)\n",
    "\n",
    "            #geometric\n",
    "            # K = max(0, math.ceil((math.log(io) - math.log(n_0)) / math.log(c)))\n",
    "\n",
    "            I_0 = list(Data_N[max(0,io-n_0):io])\n",
    "            I_k_minus1 = I_0\n",
    "            n_k_minus1 = n_0\n",
    "\n",
    "            for k in range(1, K + 1):\n",
    "                # print(f\"K={k}\")\n",
    "                # print(n_k_minus1)\n",
    "                try:\n",
    "                    #arithmetic\n",
    "                    n_k       = (k + 1) * n_0\n",
    "                    n_k_plus1 = (k + 2) * n_0\n",
    "\n",
    "                    #geometric\n",
    "                    # n_k = int(n_0 * c**k)\n",
    "                    # n_k_plus1 = int(n_0 * c**(k + 1))\n",
    "\n",
    "                    I_k = list(Data_N[max(0,io-n_k):io])\n",
    "                    I_k_plus1 = list(Data_N[max(0,io-n_k_plus1):io])\n",
    "\n",
    "                    # Pooled (observed) on I_k_plus1, out-of-sample\n",
    "                    # === Precompute all sequences for the CURRENT window I_k_plus1 once ===\n",
    "                    y_win = np.asarray(I_k_plus1, dtype=np.float32)\n",
    "                    start_abs = max(0, io - n_k_plus1)\n",
    "                    X_all, y_all, t_abs = build_sequences(y_win, seq_len, start_abs)\n",
    "                    if X_all is None:\n",
    "                        print(\"Window too small for sequences\"); continue\n",
    "                    \n",
    "                    # --- Global null fit on I_{k+1} (observed) ---\n",
    "                    SSE_I, MSE_I, m_I, yhat_I, resid_I = fit_eval_sse(\n",
    "                        X_all, y_all, epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                        hidden=LSTM_HIDDEN, layers=LSTM_LAYERS#, seed=SEED\n",
    "                    )\n",
    "\n",
    "                    # Candidate split range\n",
    "                    J_start = max(seq_len, io - n_k)   # have enough left history\n",
    "                    J_end   = io - n_k_minus1          # ensure right side at least n_0\n",
    "                    if J_end <= J_start:\n",
    "                        print(f\"J_end ({J_end}) < J_start ({J_start})\")\n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    # Candidate split range in ABSOLUTE target indices\n",
    "                    J_abs = np.arange(J_start, J_end, search_step, dtype=np.int64)\n",
    "                    \n",
    "                    T_vals = []\n",
    "                    boot_T_by_split = []   # will store bootstrap Sup over splits per replication (for efficiency)\n",
    "                    \n",
    "                    # --- Observed T(i) across splits ---\n",
    "                    for i_abs in J_abs:\n",
    "                        # Strict no-leak masks by target index\n",
    "                        Lmask = t_abs <= i_abs\n",
    "                        Rmask = t_abs >  i_abs\n",
    "                        mA = int(np.sum(Lmask)); mB = int(np.sum(Rmask))\n",
    "                        if mA < 20 or mB < 20:      # min targets per side; tune as needed\n",
    "                            T_vals.append(0.0); continue\n",
    "                    \n",
    "                        SSE_A, _, m_A, _, _ = fit_eval_sse(X_all[Lmask], y_all[Lmask],\n",
    "                                                         epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                                                         hidden=LSTM_HIDDEN, layers=LSTM_LAYERS, #seed=SEED\n",
    "                                                        )\n",
    "                        SSE_B, _, m_B, _, _ = fit_eval_sse(X_all[Rmask], y_all[Rmask],\n",
    "                                                         epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                                                         hidden=LSTM_HIDDEN, layers=LSTM_LAYERS, #seed=SEED\n",
    "                                                        )\n",
    "\n",
    "                        Ti = Likelihood_LSTM(SSE_A, m_A) + Likelihood_LSTM(SSE_B, m_B) - Likelihood_LSTM(SSE_I, m_I)\n",
    "                        T_vals.append( max(0.0, Ti) )\n",
    "                    \n",
    "                    # --- Bootstrap critical values via wild residual bootstrap under the null ---\n",
    "                    if num_bootstrap <= 0:\n",
    "                        raise ValueError(f\"Num bootstrap must be at least 1. {num_bootstrap} provided\")\n",
    "                    \n",
    "                    rng = np.random.default_rng() #SEED\n",
    "                    Sup_boot = np.empty(num_bootstrap, dtype=np.float64)  # store sup over splits for each b\n",
    "                    \n",
    "                    for b in range(num_bootstrap):\n",
    "                        # multipliers (choose Mammen or Rademacher)\n",
    "                        w = draw_mammen(len(resid_I), rng)   # or draw_rademacher(...)\n",
    "                        y_star = (yhat_I + w * resid_I).astype(np.float32)\n",
    "                    \n",
    "                        # Refit global null on y* to get SSE_I*\n",
    "                        SSE_Ib, _, m_Ib, yhat_Ib, resid_Ib = fit_eval_sse(\n",
    "                            X_all, y_star, epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                            hidden=LSTM_HIDDEN, layers=LSTM_LAYERS #, seed=SEED + b + 1\n",
    "                        )\n",
    "                    \n",
    "                        # Sweep splits and take sup\n",
    "                        sup_b = 0.0\n",
    "                        for i_abs in J_abs:\n",
    "                            Lmask = t_abs <= i_abs\n",
    "                            Rmask = t_abs >  i_abs\n",
    "                            mA = int(np.sum(Lmask)); mB = int(np.sum(Rmask))\n",
    "                            if mA < 20 or mB < 20:    # same min-seg rule\n",
    "                                continue\n",
    "                            SSE_A_b, _, m_Ab, _, _ = fit_eval_sse(X_all[Lmask], y_star[Lmask],\n",
    "                                                               epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                                                               hidden=LSTM_HIDDEN, layers=LSTM_LAYERS #, seed=SEED + b + 11\n",
    "                                                              )\n",
    "                            SSE_B_b, _, m_Bb, _, _ = fit_eval_sse(X_all[Rmask], y_star[Rmask],\n",
    "                                                               epochs=epochs, batch=LSTM_BATCH, lr=LSTM_LR,\n",
    "                                                               hidden=LSTM_HIDDEN, layers=LSTM_LAYERS #, seed=SEED + b + 21\n",
    "                                                              )\n",
    "                            \n",
    "                            Ti_b = Likelihood_LSTM(SSE_A_b, m_Ab) + Likelihood_LSTM(SSE_B_b, m_Bb) - Likelihood_LSTM(SSE_Ib, m_Ib)\n",
    "                            \n",
    "                            if Ti_b > sup_b: sup_b = Ti_b\n",
    "                        Sup_boot[b] = max(0.0, sup_b)\n",
    "                    \n",
    "                    # --- Decision for the current window ---\n",
    "                    if len(T_vals) > 0:\n",
    "                        test_value = float(np.max(T_vals))\n",
    "                        critical_value = float(np.quantile(Sup_boot, alpha))\n",
    "                        print(f\"[QLR] step={l} |I_k+1=[{max(0,io-n_k_plus1)}, {io}] | I_k=[{max(0,io-n_k)}, {io}]  |\"\n",
    "                              f\"I_k-1=[{max(0,io-n_k_minus1)}, {io}] | J_k=[{J_start}, {J_end}] | k={k} | \"\n",
    "                              f\"SupLR={test_value:.3f} | crit({alpha:.2f})={critical_value:.3f} | #splits={len(T_vals)} | B={num_bootstrap}\")\n",
    "                    else:\n",
    "                        test_value, critical_value = 0.0, math.inf\n",
    "                    \n",
    "                    if test_value > critical_value:\n",
    "                        print(f\"Found break at step {l} (window size {len(I_k)}).\")\n",
    "                        break\n",
    "                    else:\n",
    "                        I_k_minus1 = I_k\n",
    "                        n_k_minus1 = n_k\n",
    "                        continue\n",
    "\n",
    "\n",
    "                except ValueError as e:\n",
    "                    print(f\"[DEBUG] {e} | likely too-short segment\")\n",
    "                    continue\n",
    "            \n",
    "            # Record diagnostics\n",
    "            if K == 0:\n",
    "                I_k = I_0\n",
    "\n",
    "            # For the per-step diagnostic, compute OOS MSE on I_k\n",
    "            MSE_I_k = 0#segment_oos_mse(I_k, seq_len=seq_len, epochs=epochs, error_type=error_type)\n",
    "            RMSE_I_k = 0#math.sqrt(max(MSE_I_k, 0.0))\n",
    "            Likelihood_I_k = 0\n",
    "\n",
    "            windows.append(len(I_k))\n",
    "            mse_vals.append(MSE_I_k)\n",
    "            rmse_vals.append(RMSE_I_k)\n",
    "            likelihoods.append(Likelihood_I_k)\n",
    "            \n",
    "            scaled_windows.append(len(I_k) / io)\n",
    "\n",
    "            t1 = time.time()\n",
    "            print(f\"Step {l:4d} | time/step={t1 - t0:.2f}s | window={len(I_k)} | RMSE={RMSE_I_k:.4f}\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"[DEBUG] {e} | skipping step {l}\")\n",
    "            windows.append(np.nan); mse_vals.append(np.nan); rmse_vals.append(np.nan); scaled_windows.append(np.nan)\n",
    "            continue\n",
    "\n",
    "    # Reverse to align like your original flow\n",
    "    windows.reverse(); mse_vals.reverse(); rmse_vals.reverse(); scaled_windows.reverse()\n",
    "    DT_N[\"windows_1\"]        = pd.Series(windows)\n",
    "    DT_N[\"scaled_windows_1\"] = pd.Series(scaled_windows)\n",
    "    DT_N[\"MSE_lstm_1\"]       = pd.Series(mse_vals)\n",
    "    DT_N[\"RMSE_lstm_1\"]      = pd.Series(rmse_vals)\n",
    "\n",
    "    return DT_N, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a46a72-e828-4dc2-88d0-bab153790c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data. Generated with: https://github.com/QuantLet/AR_sim_p/tree/main\n",
    "df = pd.read_csv(\"LPA/Simulation/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5761b-0783-47f1-b3e2-7ff4bf7b162c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN 1/10 ===\n",
      "[QLR] step=0 |I_k+1=[1200, 1500] | I_k=[1300, 1500]  |I_k-1=[1400, 1500] | J_k=[1300, 1400] | k=1 | SupLR=90.706 | crit(0.95)=84.310 | #splits=10 | B=10\n",
      "Found break at step 0 (window size 200).\n",
      "Step    0 | time/step=5.07s | window=200 | RMSE=0.0000\n",
      "[QLR] step=50 |I_k+1=[1150, 1450] | I_k=[1250, 1450]  |I_k-1=[1350, 1450] | J_k=[1250, 1350] | k=1 | SupLR=85.589 | crit(0.95)=93.273 | #splits=10 | B=10\n",
      "[QLR] step=50 |I_k+1=[1050, 1450] | I_k=[1150, 1450]  |I_k-1=[1250, 1450] | J_k=[1150, 1250] | k=2 | SupLR=119.165 | crit(0.95)=131.054 | #splits=10 | B=10\n",
      "[QLR] step=50 |I_k+1=[950, 1450] | I_k=[1050, 1450]  |I_k-1=[1150, 1450] | J_k=[1050, 1150] | k=3 | SupLR=221.479 | crit(0.95)=196.624 | #splits=10 | B=10\n",
      "Found break at step 50 (window size 400).\n",
      "Step   50 | time/step=19.29s | window=400 | RMSE=0.0000\n",
      "[QLR] step=100 |I_k+1=[1100, 1400] | I_k=[1200, 1400]  |I_k-1=[1300, 1400] | J_k=[1200, 1300] | k=1 | SupLR=76.155 | crit(0.95)=93.132 | #splits=10 | B=10\n",
      "[QLR] step=100 |I_k+1=[1000, 1400] | I_k=[1100, 1400]  |I_k-1=[1200, 1400] | J_k=[1100, 1200] | k=2 | SupLR=122.521 | crit(0.95)=139.561 | #splits=10 | B=10\n",
      "[QLR] step=100 |I_k+1=[900, 1400] | I_k=[1000, 1400]  |I_k-1=[1100, 1400] | J_k=[1000, 1100] | k=3 | SupLR=248.506 | crit(0.95)=186.479 | #splits=10 | B=10\n",
      "Found break at step 100 (window size 400).\n",
      "Step  100 | time/step=19.70s | window=400 | RMSE=0.0000\n",
      "[QLR] step=150 |I_k+1=[1050, 1350] | I_k=[1150, 1350]  |I_k-1=[1250, 1350] | J_k=[1150, 1250] | k=1 | SupLR=68.221 | crit(0.95)=85.563 | #splits=10 | B=10\n",
      "[QLR] step=150 |I_k+1=[950, 1350] | I_k=[1050, 1350]  |I_k-1=[1150, 1350] | J_k=[1050, 1150] | k=2 | SupLR=171.349 | crit(0.95)=157.488 | #splits=10 | B=10\n",
      "Found break at step 150 (window size 300).\n",
      "Step  150 | time/step=11.67s | window=300 | RMSE=0.0000\n",
      "[QLR] step=200 |I_k+1=[1000, 1300] | I_k=[1100, 1300]  |I_k-1=[1200, 1300] | J_k=[1100, 1200] | k=1 | SupLR=87.007 | crit(0.95)=102.189 | #splits=10 | B=10\n",
      "[QLR] step=200 |I_k+1=[900, 1300] | I_k=[1000, 1300]  |I_k-1=[1100, 1300] | J_k=[1000, 1100] | k=2 | SupLR=208.520 | crit(0.95)=150.124 | #splits=10 | B=10\n",
      "Found break at step 200 (window size 300).\n",
      "Step  200 | time/step=11.63s | window=300 | RMSE=0.0000\n",
      "[QLR] step=250 |I_k+1=[950, 1250] | I_k=[1050, 1250]  |I_k-1=[1150, 1250] | J_k=[1050, 1150] | k=1 | SupLR=126.960 | crit(0.95)=118.606 | #splits=10 | B=10\n",
      "Found break at step 250 (window size 200).\n",
      "Step  250 | time/step=5.10s | window=200 | RMSE=0.0000\n",
      "[QLR] step=300 |I_k+1=[900, 1200] | I_k=[1000, 1200]  |I_k-1=[1100, 1200] | J_k=[1000, 1100] | k=1 | SupLR=157.609 | crit(0.95)=102.541 | #splits=10 | B=10\n",
      "Found break at step 300 (window size 200).\n",
      "Step  300 | time/step=5.06s | window=200 | RMSE=0.0000\n",
      "[QLR] step=350 |I_k+1=[850, 1150] | I_k=[950, 1150]  |I_k-1=[1050, 1150] | J_k=[950, 1050] | k=1 | SupLR=146.044 | crit(0.95)=105.487 | #splits=10 | B=10\n",
      "Found break at step 350 (window size 200).\n",
      "Step  350 | time/step=5.05s | window=200 | RMSE=0.0000\n",
      "[QLR] step=400 |I_k+1=[800, 1100] | I_k=[900, 1100]  |I_k-1=[1000, 1100] | J_k=[900, 1000] | k=1 | SupLR=125.287 | crit(0.95)=99.261 | #splits=10 | B=10\n",
      "Found break at step 400 (window size 200).\n",
      "Step  400 | time/step=5.07s | window=200 | RMSE=0.0000\n",
      "[QLR] step=450 |I_k+1=[750, 1050] | I_k=[850, 1050]  |I_k-1=[950, 1050] | J_k=[850, 950] | k=1 | SupLR=70.039 | crit(0.95)=82.752 | #splits=10 | B=10\n",
      "[QLR] step=450 |I_k+1=[650, 1050] | I_k=[750, 1050]  |I_k-1=[850, 1050] | J_k=[750, 850] | k=2 | SupLR=106.843 | crit(0.95)=125.600 | #splits=10 | B=10\n",
      "[QLR] step=450 |I_k+1=[550, 1050] | I_k=[650, 1050]  |I_k-1=[750, 1050] | J_k=[650, 750] | k=3 | SupLR=138.897 | crit(0.95)=144.587 | #splits=10 | B=10\n",
      "[QLR] step=450 |I_k+1=[450, 1050] | I_k=[550, 1050]  |I_k-1=[650, 1050] | J_k=[550, 650] | k=4 | SupLR=164.933 | crit(0.95)=167.311 | #splits=10 | B=10\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Example: repeat experiment num_runs times\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= experiment config =======\n",
    "    num_runs  = 10     # total repetitions of the whole experiment\n",
    "    boot_B    = 10      \n",
    "    alpha     = 0.95\n",
    "    n_0       = 100\n",
    "    search_step = 10 #int(n_0 / 5)\n",
    "    epochs    = 50\n",
    "    jump=50\n",
    "    # =================================\n",
    "\n",
    "    dir_path = f\"LPA/Simulation/Jump_{jump}_N0_{n_0}\"\n",
    "    try:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "    n_total = 1500\n",
    "    coeffs = [\n",
    "        (0.9,  0.01, 0.01),\n",
    "        (0.01, 0.9,  0.01),\n",
    "        (0.01, 0.01, 0.9),\n",
    "    ]\n",
    "    change_points = [0, 500, 1000]\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"\\n=== RUN {run+1}/{num_runs} ===\")\n",
    "\n",
    "        Data_N = df[\"N\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "        DT_out, total_tests = detect_changes_with_lstm(\n",
    "            Data_N,\n",
    "            seq_len=LSTM_SEQ_LEN,\n",
    "            n_0=n_0,\n",
    "            jump=jump,\n",
    "            search_step=search_step,\n",
    "            c=1.35,\n",
    "            alpha=alpha,\n",
    "            num_bootstrap=boot_B,\n",
    "            epochs=LSTM_EPOCHS,\n",
    "            val_frac=0.2\n",
    "        )\n",
    "        out_name = f\"{dir_path}/LSTM_{n_total}_run{run:03d}_n{n_0}_alpha{alpha}_bootB{boot_B}.csv\"\n",
    "        DT_out.to_csv(out_name, index=False)\n",
    "        print(f\"Saved results to: {out_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a93d18-0510-482e-b791-2189117ccf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
